#!/usr/bin/env bash

# Generate a schema snapshot from all migrations for CI use
# This allows CI to skip large LFS migration files by loading a pre-generated schema

set -e

cd $(git rev-parse --show-toplevel)

echo "=== GENERATING SCHEMA SNAPSHOT FROM MIGRATIONS ==="

# Check if we have a local database
if ! command -v psql &> /dev/null; then
    echo "ERROR: psql is not installed"
    exit 1
fi

# Configuration
SNAPSHOT_DB="d4ad_snapshot_temp"
SNAPSHOT_FILE="backend/schema-snapshot.sql"
SNAPSHOT_DATA_FILE="backend/schema-snapshot-with-seed-data.sql"

# Ensure we have the .env file
if [ ! -f backend/.env ]; then
    echo "ERROR: backend/.env file not found"
    echo "Please create backend/.env with your database credentials"
    exit 1
fi

source ./backend/.env

# Use the dev environment settings
export NODE_ENV=dev
HOST_ENV_VAR=$(jq -r ".dev.writer.host.ENV" backend/database.json)
PASSWORD_ENV_VAR=$(jq -r ".dev.writer.password.ENV" backend/database.json)

DB_HOST=${!HOST_ENV_VAR}
DB_PASSWORD=${!PASSWORD_ENV_VAR}

echo "Creating temporary database: $SNAPSHOT_DB"
# Drop if exists and create fresh
PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U postgres -c "DROP DATABASE IF EXISTS $SNAPSHOT_DB;" postgres
PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U postgres -c "CREATE DATABASE $SNAPSHOT_DB;" postgres

echo "Running all migrations on temporary database..."
# Temporarily update database.json to use snapshot database
TEMP_DB_JSON=$(mktemp)
jq ".dev.writer.database = \"$SNAPSHOT_DB\" | .dev.database = \"$SNAPSHOT_DB\"" backend/database.json > "$TEMP_DB_JSON"
cp backend/database.json backend/database.json.backup
cp "$TEMP_DB_JSON" backend/database.json

# Run migrations
DATABASE_URL="postgresql://postgres:${DB_PASSWORD}@${DB_HOST}:5432/${SNAPSHOT_DB}"
export DATABASE_URL

echo "Running db-migrate up..."
npm --prefix=backend run db-migrate up

# Restore original database.json
mv backend/database.json.backup backend/database.json
rm "$TEMP_DB_JSON"

echo "Generating schema-only dump..."
PGPASSWORD="$DB_PASSWORD" pg_dump \
    -h "$DB_HOST" \
    -U postgres \
    -d "$SNAPSHOT_DB" \
    --schema-only \
    --no-owner \
    --no-acl \
    --no-privileges \
    --no-tablespaces \
    --no-security-labels \
    --no-comments \
    > "$SNAPSHOT_FILE"

echo "Generating schema + seed data dump..."
PGPASSWORD="$DB_PASSWORD" pg_dump \
    -h "$DB_HOST" \
    -U postgres \
    -d "$SNAPSHOT_DB" \
    --no-owner \
    --no-acl \
    --no-privileges \
    --no-tablespaces \
    --no-security-labels \
    > "$SNAPSHOT_DATA_FILE"

# Clean up
echo "Dropping temporary database..."
PGPASSWORD="$DB_PASSWORD" psql -h "$DB_HOST" -U postgres -c "DROP DATABASE IF EXISTS $SNAPSHOT_DB;" postgres

# Add metadata header
TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
MIGRATION_COUNT=$(ls -1 backend/migrations/*.js 2>/dev/null | wc -l | tr -d ' ')

sed -i.bak "1i\\
-- Database Schema Snapshot for CI\\
-- Generated: $TIMESTAMP\\
-- Migrations included: $MIGRATION_COUNT\\
-- Generated by: scripts/generate-schema-snapshot.sh\\
--\\
-- This file is automatically generated from all migrations.\\
-- DO NOT EDIT MANUALLY - Run ./scripts/generate-schema-snapshot.sh to regenerate\\
--\\
" "$SNAPSHOT_FILE"

sed -i.bak "1i\\
-- Database Schema + Seed Data Snapshot for CI\\
-- Generated: $TIMESTAMP\\
-- Migrations included: $MIGRATION_COUNT\\
-- Generated by: scripts/generate-schema-snapshot.sh\\
--\\
-- This file is automatically generated from all migrations.\\
-- DO NOT EDIT MANUALLY - Run ./scripts/generate-schema-snapshot.sh to regenerate\\
--\\
" "$SNAPSHOT_DATA_FILE"

rm "$SNAPSHOT_FILE.bak" "$SNAPSHOT_DATA_FILE.bak"

echo "=== SCHEMA SNAPSHOT GENERATED SUCCESSFULLY ==="
echo "Schema-only file: $SNAPSHOT_FILE ($(wc -c < "$SNAPSHOT_FILE" | numfmt --to=iec))"
echo "Schema + data file: $SNAPSHOT_DATA_FILE ($(wc -c < "$SNAPSHOT_DATA_FILE" | numfmt --to=iec))"
echo ""
echo "Next steps:"
echo "1. Review the generated files"
echo "2. git add $SNAPSHOT_FILE $SNAPSHOT_DATA_FILE"
echo "3. git commit -m 'chore: update schema snapshot from migrations'"
echo ""
echo "The CI workflow will use these files instead of running migrations with large LFS files"
